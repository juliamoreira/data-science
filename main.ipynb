{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwufnHfvfSwv",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Final Report - Data Science\n",
        "## Bachelor's Degree in Computer Science / PUCPR\n",
        "\n",
        "**Prof. Jean Paul Barddal** / **Prof. Rayson Laroca**\n",
        "\n",
        "`Guilherme Schwarz` - `guilherme.schwarz@pucpr.edu.br`\n",
        "\n",
        "`Julia Cristina Moreira da Silva` - `s.moreira4@pucpr.edu.br`\n",
        "\n",
        "`2025`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68-F6cD9VL-J",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Imports & Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "itrIGnaaVQnH",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
            "Requirement already satisfied: pydub in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.25.1)\n",
            "Requirement already satisfied: soundfile in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.61.2)\n",
            "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.24.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (5.1.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lazy_loader>=0.1->librosa) (23.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.1->librosa) (2.28.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chico\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "%pip install librosa tqdm pydub soundfile\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTP1pmiPgDY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Data & Data Treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-VCzmIHcgA2P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "AUDIO_DIR = 'Data/flac/'\n",
        "PROTOCOL_PATH = 'Data/ASVspoof2021Protocol.txt'\n",
        "OUTPUT_PATH = 'Data/asvspoof_features.csv'\n",
        "SAMPLE_OUTPUT_PATH = 'Data/sample_features.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Treatment Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract MFCCs\n",
        "def extract_mfcc(y, sr, n_mfcc=13):\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "    return np.mean(mfcc, axis=1)\n",
        "\n",
        "# Function to extract log-Mel spectrogram\n",
        "def extract_logmel(y, sr, n_mels=128):\n",
        "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    logmel = librosa.power_to_db(mel)\n",
        "    return np.mean(logmel, axis=1)\n",
        "\n",
        "# Function to extract LFCCs\n",
        "def extract_lfcc(y, sr, n_lfcc=20):\n",
        "    # Compute the Short-Time Fourier Transform (STFT)\n",
        "    stft = np.abs(librosa.stft(y))\n",
        "    # Apply a linear filter bank\n",
        "    linear_fb = np.linspace(0, sr / 2, n_lfcc + 2)\n",
        "    lfcc = librosa.feature.mfcc(S=librosa.power_to_db(stft), sr=sr, n_mfcc=n_lfcc)\n",
        "    return np.mean(lfcc, axis=1)\n",
        "\n",
        "def extract_features(y, sr):\n",
        "    mfcc = extract_mfcc(y, sr)\n",
        "    logmel = extract_logmel(y, sr)\n",
        "    lfcc = extract_lfcc(y, sr)\n",
        "    return np.concatenate([mfcc, logmel, lfcc])\n",
        "\n",
        "def process_audio_row(row, audio_dir):\n",
        "    file_path = os.path.join(audio_dir, row['file_name'] + '.flac')\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=None)  # load_audio_pydub(file_path)\n",
        "        features = extract_features(y, sr)\n",
        "\n",
        "        return {\n",
        "            'file_name': row['file_name'],\n",
        "            'label': 1 if row['label'] == 'bonafide' else 0,\n",
        "            **{f'feature_{i+1}': val for i, val in enumerate(features)}\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Protocol File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>file_name</th>\n",
              "      <th>codec</th>\n",
              "      <th>source_db</th>\n",
              "      <th>system_id</th>\n",
              "      <th>label</th>\n",
              "      <th>trim_status</th>\n",
              "      <th>set_type</th>\n",
              "      <th>spoof_category</th>\n",
              "      <th>track</th>\n",
              "      <th>team</th>\n",
              "      <th>subset</th>\n",
              "      <th>group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LA_0023</td>\n",
              "      <td>DF_E_2000011</td>\n",
              "      <td>nocodec</td>\n",
              "      <td>asvspoof</td>\n",
              "      <td>A14</td>\n",
              "      <td>spoof</td>\n",
              "      <td>notrim</td>\n",
              "      <td>progress</td>\n",
              "      <td>traditional_vocoder</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEF2</td>\n",
              "      <td>DF_E_2000013</td>\n",
              "      <td>low_m4a</td>\n",
              "      <td>vcc2020</td>\n",
              "      <td>Task1-team20</td>\n",
              "      <td>spoof</td>\n",
              "      <td>notrim</td>\n",
              "      <td>eval</td>\n",
              "      <td>neural_vocoder_nonautoregressive</td>\n",
              "      <td>Task1</td>\n",
              "      <td>team20</td>\n",
              "      <td>FF</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TGF1</td>\n",
              "      <td>DF_E_2000024</td>\n",
              "      <td>mp3m4a</td>\n",
              "      <td>vcc2020</td>\n",
              "      <td>Task2-team12</td>\n",
              "      <td>spoof</td>\n",
              "      <td>notrim</td>\n",
              "      <td>eval</td>\n",
              "      <td>traditional_vocoder</td>\n",
              "      <td>Task2</td>\n",
              "      <td>team12</td>\n",
              "      <td>FF</td>\n",
              "      <td>G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LA_0043</td>\n",
              "      <td>DF_E_2000026</td>\n",
              "      <td>mp3m4a</td>\n",
              "      <td>asvspoof</td>\n",
              "      <td>A09</td>\n",
              "      <td>spoof</td>\n",
              "      <td>notrim</td>\n",
              "      <td>eval</td>\n",
              "      <td>traditional_vocoder</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LA_0021</td>\n",
              "      <td>DF_E_2000027</td>\n",
              "      <td>mp3m4a</td>\n",
              "      <td>asvspoof</td>\n",
              "      <td>A12</td>\n",
              "      <td>spoof</td>\n",
              "      <td>notrim</td>\n",
              "      <td>eval</td>\n",
              "      <td>neural_vocoder_autoregressive</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id     file_name    codec source_db     system_id  label trim_status  \\\n",
              "0  LA_0023  DF_E_2000011  nocodec  asvspoof           A14  spoof      notrim   \n",
              "1     TEF2  DF_E_2000013  low_m4a   vcc2020  Task1-team20  spoof      notrim   \n",
              "2     TGF1  DF_E_2000024   mp3m4a   vcc2020  Task2-team12  spoof      notrim   \n",
              "3  LA_0043  DF_E_2000026   mp3m4a  asvspoof           A09  spoof      notrim   \n",
              "4  LA_0021  DF_E_2000027   mp3m4a  asvspoof           A12  spoof      notrim   \n",
              "\n",
              "   set_type                    spoof_category  track    team subset group  \n",
              "0  progress               traditional_vocoder      -       -      -     -  \n",
              "1      eval  neural_vocoder_nonautoregressive  Task1  team20     FF     E  \n",
              "2      eval               traditional_vocoder  Task2  team12     FF     G  \n",
              "3      eval               traditional_vocoder      -       -      -     -  \n",
              "4      eval     neural_vocoder_autoregressive      -       -      -     -  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "protocol = pd.read_csv(PROTOCOL_PATH, sep=' ', header=None)\n",
        "protocol.columns = [\n",
        "    \"id\", \"file_name\", \"codec\", \"source_db\", \"system_id\", \"label\",\n",
        "    \"trim_status\", \"set_type\", \"spoof_category\",\n",
        "    \"track\", \"team\", \"subset\", \"group\"\n",
        "]\n",
        "\n",
        "protocol.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process 100 files to create a sample and benchmark process (if not already done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting:   0%|          | 0/611829 [00:00<?, ?it/s]C:\\Users\\Chico\\AppData\\Local\\Temp\\ipykernel_21132\\2066705946.py:34: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(file_path, sr=None)  # load_audio_pydub(file_path)\n",
            "c:\\Users\\Chico\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "Extracting:   0%|          | 99/611829 [00:03<6:40:20, 25.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processed 100 files.\n",
            "Total time: 3.85 seconds\n",
            "Average time per file: 0.0385 seconds\n",
            "Expected time for whole feature extraction: 6.540861457407475 hours\n",
            "Sample features saved to Data/sample_features.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(SAMPLE_OUTPUT_PATH):\n",
        "    features_list = []\n",
        "    num_files = 100\n",
        "    processed = 0\n",
        "    total_time = 0\n",
        "\n",
        "    for _, row in tqdm(protocol.iterrows(), total=len(protocol), desc=\"Extracting\"):\n",
        "        start_time = time.time()\n",
        "        result = process_audio_row(row, AUDIO_DIR)\n",
        "        elapsed = time.time() - start_time\n",
        "        if result is not None:\n",
        "            features_list.append(result)\n",
        "            total_time += elapsed\n",
        "            processed += 1\n",
        "        if processed >= num_files:\n",
        "            break\n",
        "\n",
        "    # Save features to CSV\n",
        "    if features_list:\n",
        "        average_time = total_time / processed\n",
        "        features_df = pd.DataFrame(features_list)\n",
        "        features_df.to_csv(SAMPLE_OUTPUT_PATH, index=False)\n",
        "        print(f\"\\nProcessed {processed} files.\")\n",
        "        print(f\"Total time: {total_time:.2f} seconds\")\n",
        "        print(f\"Average time per file: {average_time:.4f} seconds\")\n",
        "        print(f\"Expected time for whole feature extraction: {average_time * len(protocol) / 3600} hours\")\n",
        "        print(f\"Sample features saved to {SAMPLE_OUTPUT_PATH}\")\n",
        "    else:\n",
        "        print(\"No features extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create CSV from audio files (if not already created)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/611829 [00:00<?, ?it/s]C:\\Users\\Chico\\AppData\\Local\\Temp\\ipykernel_21132\\2066705946.py:34: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y, sr = librosa.load(file_path, sr=None)  # load_audio_pydub(file_path)\n",
            "c:\\Users\\Chico\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "100%|██████████| 611829/611829 [7:31:17<00:00, 22.60it/s]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed 611829 files. Features saved to Data/asvspoof_features.csv\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(OUTPUT_PATH):\n",
        "    features_list = []\n",
        "    for _, row in tqdm(protocol.iterrows(), total=len(protocol)):\n",
        "        result = process_audio_row(row, AUDIO_DIR)\n",
        "        if result is not None:\n",
        "            features_list.append(result)\n",
        "\n",
        "    if features_list:\n",
        "        features_df = pd.DataFrame(features_list)\n",
        "        features_df.to_csv(OUTPUT_PATH, index=False)\n",
        "        print(f\"Processed {len(features_list)} files. Features saved to {OUTPUT_PATH}\")\n",
        "    else:\n",
        "        print(\"No features extracted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "8R3Z5xgWyj1i"
      },
      "source": [
        "# Statistical Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ULcpwDnOyj1i"
      },
      "source": [
        "In this section, you should report the key characteristics of the dataset, including but not limited to:\n",
        "* Number of instances;\n",
        "* Number of features;\n",
        "* Number of classes;\n",
        "* Class distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "y5IFTWiTyj1i"
      },
      "outputs": [],
      "source": [
        "# use as many code and text cells as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX9sOXW1gOCU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Univariate data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQljrblLzQQz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In this section, you should perform univariate data analysis on at least **20 variables**.\n",
        "\n",
        "In the end, you should describe the main variables that are of your interest, and these should be accounted for in the next sections of the report.\n",
        "The definition of each variable chosen should be clarified, so arbitrary selections are **not** accepted at this point.\n",
        "\n",
        "For each variable plotted, make sure you determine the following:\n",
        "1. The distribution of the data (Gaussian, binomial, exponential, etc.);\n",
        "2. Skewness;\n",
        "3. Kurtosis;\n",
        "4. Mean, standard deviation, and what they stand for in the context of the dataset.\n",
        "\n",
        "Ensure that each variable is **plotted correctly** based on its type. For instance, make sure scatterplots are not used for categorical data and so forth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "BWS2-FMfgWJR",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# place as many cells to plot the visualizations,\n",
        "# as well as to describe the main findings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zACQ5EROmhM5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# if you realize you need to further clean your data here, there is no problem,\n",
        "# yet, make sure you are describing the entire process and the rationale\n",
        "# behind your choices here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAVrOW1tgQU7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Multivariate data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD7VaU40z_sN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In this section, you should plot at least **5 multivariate visualizations**. The key here is to investigate underlying correlations and behaviors within the dataset.\n",
        "Naturally, as visualizations are being created, we should end up with obvious results, yet, you should find at least **ONE** non-obvious behavior in the data.\n",
        "\n",
        "Please follow these steps for creating your visualizations:\n",
        "1. State an hypothesis. Explain why you have selected these specific variables and what you expect to discover through their relationship;\n",
        "2. Determine what kind of visualization is the most suitable;\n",
        "3. Report the findings and discuss whether they corroborate or not the aforementioned hypothesis.\n",
        "\n",
        "\n",
        "### Hints\n",
        "\n",
        "In this section, make sure you go beyond naive explorations. For example, consider applying techniques such as PCA, t-SNE, or even others that we haven't covered in the lectures. The goal is to cultivate a critical mindset toward data analysis and our work.\n",
        "\n",
        "### Important\n",
        "\n",
        "It is strictly prohibited to create multivariate visualizations using variables that were not included in the previous section (univariate data analysis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "fp4ct7TngWmF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# again, feel free to place as many cells to plot the visualizations,\n",
        "# as well as describe to the main findings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehWz8rAcgZ0c",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Final Plots (Effective Data Visualization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHyF3RvU2q9r",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In this section, you need to **enhance 3 multivariate visualizations** that were presented in the previous section of the report.\n",
        "The goal is to enhance these visualizations so that they can be effectively presented to an audience unfamiliar with the dataset or with data analysis.\n",
        "**Therefore, make sure that their size, colors, textures, and other visual elements are appropriate and convey the intended information to the audience.**\n",
        "\n",
        "For your final plots, make sure you follow these steps:\n",
        "1. Present the plot;\n",
        "2. Provide a description of the visualization, highlighting the key findings that can be drawn from it.\n",
        "\n",
        "\n",
        "**Hint**: take a look at the checklist based on Evergreen’s work to ensure your visualizations meet the best practices for clarity and impact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "K90_0h6JgfnW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ua7B5nTmgbN7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Digest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJ0cqdoj4Lg7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In this section you should write down the main findings of this exploratory data analysis. Furthermore, you should provide a reflection about your own work and effort during the module, highlighting what you believe you have done well and what you should have done differently. This digest should have at least 2,500 characters (excluding spaces)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQWFN0TEPUzp",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "```\n",
        "Add your text here.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDlyU2X8yj1j"
      },
      "source": [
        "# Machine Learning (**post checkpoint!**)\n",
        "\n",
        "In this section, you must create at least **3 machine learning models** for the task at hand. Depending on the problem's nature, you must select from classification, regression, or clustering models.\n",
        "It is also important that you:\n",
        "* Select **an appropriate validation protocol**, providing a rationale for why it is appropriate for this specific task;\n",
        "* Choose **a suitable set of evaluation metrics**, providing an explanation for each and describing how it contributes to evaluating the model's performance in the context of this specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wmLE99R_yj1k"
      },
      "outputs": [],
      "source": [
        "# use as many cells as needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CaFQEil1F6Q",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Final Steps (Submission)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2R5Kily1H7f",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "1. Save this report as a Jupyter Notebook (`.ipynb`);\n",
        "2. Export a copy of the report as a PDF file (`.pdf`);\n",
        "3. Copy the dataset;\n",
        "4. Compress all the files (the Jupyter Notebook, PDF, and dataset) into a single ZIP archive (`<your_team_name>.zip`);\n",
        "5. Upload the ZIP file to AVA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge-rZWsIyj1k",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
